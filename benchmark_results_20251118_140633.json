[
  {
    "prompt": "What is AI?",
    "num_requests": 100,
    "timestamp": "2025-11-18T13:19:27.238246",
    "latency_seconds": {
      "count": 100,
      "min": 2.248852014541626,
      "max": 13.373247146606445,
      "mean": 9.419030859470368,
      "median": 9.552732944488525,
      "stdev": 1.7724214153777076,
      "p50": 9.55487322807312,
      "p90": 11.508890390396118,
      "p95": 11.839401960372925,
      "p99": 13.373247146606445
    },
    "tokens_per_second": {
      "count": 100,
      "min": 48.57019360632889,
      "max": 51.36093472933209,
      "mean": 49.53415443093154,
      "median": 49.497757445343105,
      "stdev": 0.431236554059253,
      "p50": 49.50563107431448,
      "p90": 49.98469672554044,
      "p95": 50.233464654740835,
      "p99": 51.36093472933209
    },
    "time_to_first_token_seconds": {
      "count": 100,
      "min": 0.019735799,
      "max": 0.039103503,
      "mean": 0.02017756284,
      "median": 0.019956482999999997,
      "stdev": 0.0019212908744122403,
      "p50": 0.019957738,
      "p90": 0.020228559,
      "p95": 0.020455848,
      "p99": 0.039103503
    },
    "total_tokens_generated": 44540,
    "avg_tokens_per_request": 445.4
  },
  {
    "prompt": "Explain the concept of machine learning in simple terms.",
    "num_requests": 100,
    "timestamp": "2025-11-18T13:32:32.337399",
    "latency_seconds": {
      "count": 100,
      "min": 6.097766637802124,
      "max": 10.228542804718018,
      "mean": 7.830817840099335,
      "median": 7.782675504684448,
      "stdev": 0.8281702204259829,
      "p50": 7.783627033233643,
      "p90": 8.82211446762085,
      "p95": 9.784984350204468,
      "p99": 10.228542804718018
    },
    "tokens_per_second": {
      "count": 100,
      "min": 49.20615681211757,
      "max": 50.71251484836022,
      "mean": 49.94471388365948,
      "median": 49.90392161022989,
      "stdev": 0.3073277460579215,
      "p50": 49.904695794373914,
      "p90": 50.333959988703604,
      "p95": 50.45018908203237,
      "p99": 50.71251484836022
    },
    "time_to_first_token_seconds": {
      "count": 100,
      "min": 0.019624681,
      "max": 0.04055884,
      "mean": 0.02009617596,
      "median": 0.019879083999999998,
      "stdev": 0.002072151574134474,
      "p50": 0.019885888,
      "p90": 0.020115736,
      "p95": 0.020192388,
      "p99": 0.04055884
    },
    "total_tokens_generated": 37288,
    "avg_tokens_per_request": 372.88
  },
  {
    "prompt": "Describe the architecture of a transformer model and explain how self-attention works.",
    "num_requests": 100,
    "timestamp": "2025-11-18T14:06:31.797052",
    "latency_seconds": {
      "count": 100,
      "min": 14.108544111251831,
      "max": 29.58432102203369,
      "mean": 20.374357564449312,
      "median": 20.12221133708954,
      "stdev": 3.358106846181639,
      "p50": 20.12284278869629,
      "p90": 24.802423000335693,
      "p95": 28.224928379058838,
      "p99": 29.58432102203369
    },
    "tokens_per_second": {
      "count": 100,
      "min": 46.84789829115077,
      "max": 49.153550717794474,
      "mean": 48.10260705867497,
      "median": 48.140441352387434,
      "stdev": 0.49298208573618196,
      "p50": 48.142491347850154,
      "p90": 48.74341462678344,
      "p95": 48.9431954294234,
      "p99": 49.153550717794474
    },
    "time_to_first_token_seconds": {
      "count": 100,
      "min": 0.019639524,
      "max": 0.04775565,
      "mean": 0.02007117237,
      "median": 0.0197554355,
      "stdev": 0.0027995878871497834,
      "p50": 0.019756689,
      "p90": 0.019958566,
      "p95": 0.02003543,
      "p99": 0.04775565
    },
    "total_tokens_generated": 94755,
    "avg_tokens_per_request": 947.55
  }
]