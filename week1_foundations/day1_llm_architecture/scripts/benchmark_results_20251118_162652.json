[
  {
    "prompt": "What is AI?",
    "num_requests": 100,
    "timestamp": "2025-11-18T15:39:04.289675",
    "latency_seconds": {
      "count": 100,
      "min": 4.018580198287964,
      "max": 14.713088750839233,
      "mean": 9.590195198059082,
      "median": 9.704364657402039,
      "stdev": 1.9735858849332581,
      "p50": 9.714192390441895,
      "p90": 12.05701994895935,
      "p95": 13.204784870147705,
      "p99": 14.713088750839233
    },
    "tokens_per_second": {
      "count": 100,
      "min": 48.41948587878592,
      "max": 50.83967995045622,
      "mean": 49.462344566246095,
      "median": 49.42641586255988,
      "stdev": 0.4240484574523088,
      "p50": 49.42901783339768,
      "p90": 50.033822740901115,
      "p95": 50.101463755657356,
      "p99": 50.83967995045622
    },
    "time_to_first_token_seconds": {
      "count": 100,
      "min": 0.019658592,
      "max": 0.040421026,
      "mean": 0.02550267577,
      "median": 0.020088600499999998,
      "stdev": 0.008834160289211426,
      "p50": 0.020089922,
      "p90": 0.039655443,
      "p95": 0.039816279,
      "p99": 0.040421026
    },
    "total_tokens_generated": 45123,
    "avg_tokens_per_request": 451.23
  },
  {
    "prompt": "Explain the concept of machine learning in simple terms.",
    "num_requests": 100,
    "timestamp": "2025-11-18T15:52:28.284711",
    "latency_seconds": {
      "count": 100,
      "min": 6.133831977844238,
      "max": 11.069061994552612,
      "mean": 8.019771134853363,
      "median": 7.860616087913513,
      "stdev": 0.9924407404233062,
      "p50": 7.87277889251709,
      "p90": 9.514304876327515,
      "p95": 9.827483654022217,
      "p99": 11.069061994552612
    },
    "tokens_per_second": {
      "count": 100,
      "min": 49.38770866030338,
      "max": 50.73078443036044,
      "mean": 50.238476053501586,
      "median": 50.27587131134602,
      "stdev": 0.27845991329085534,
      "p50": 50.279168331119315,
      "p90": 50.53476428222654,
      "p95": 50.60127002168174,
      "p99": 50.73078443036044
    },
    "time_to_first_token_seconds": {
      "count": 100,
      "min": 0.019582198,
      "max": 0.04080078,
      "mean": 0.02492562043,
      "median": 0.019807108,
      "stdev": 0.008904332767010225,
      "p50": 0.019807304,
      "p90": 0.040286083,
      "p95": 0.040380393,
      "p99": 0.04080078
    },
    "total_tokens_generated": 38296,
    "avg_tokens_per_request": 382.96
  },
  {
    "prompt": "Describe the architecture of a transformer model and explain how self-attention works.",
    "num_requests": 100,
    "timestamp": "2025-11-18T16:26:50.764731",
    "latency_seconds": {
      "count": 100,
      "min": 12.69572901725769,
      "max": 34.933528423309326,
      "mean": 20.604562430381776,
      "median": 19.800055980682373,
      "stdev": 3.7992911412064396,
      "p50": 19.820413827896118,
      "p90": 25.832797527313232,
      "p95": 26.89068102836609,
      "p99": 34.933528423309326
    },
    "tokens_per_second": {
      "count": 100,
      "min": 46.39235145300302,
      "max": 49.28540350901874,
      "mean": 48.148658825267226,
      "median": 48.26048768988237,
      "stdev": 0.5359777320867102,
      "p50": 48.264771327316424,
      "p90": 48.76146092922993,
      "p95": 48.87452322864459,
      "p99": 49.28540350901874
    },
    "time_to_first_token_seconds": {
      "count": 100,
      "min": 0.019630189,
      "max": 0.048602221,
      "mean": 0.03435128072,
      "median": 0.0475030885,
      "stdev": 0.013969869210262779,
      "p50": 0.047515869,
      "p90": 0.04782432,
      "p95": 0.047870138,
      "p99": 0.048602221
    },
    "total_tokens_generated": 95557,
    "avg_tokens_per_request": 955.57
  }
]